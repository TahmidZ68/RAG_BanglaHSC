{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c20503c783d44449e1cf29520099e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48bed49dbc29449f94a3719c43c00f9f",
              "IPY_MODEL_74bae842b3ee40f8a483721f0907e250",
              "IPY_MODEL_0fefd2e7d9dc4cd290241112dc2f1323"
            ],
            "layout": "IPY_MODEL_aeeccda9cd0b4d1aa5c2d55bc352c372"
          }
        },
        "48bed49dbc29449f94a3719c43c00f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29deab1d5a4e4492ac0d5ee977ce5f68",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ffd6e7a36436452ca182ee20c72a5feb",
            "value": "Batches:‚Äá100%"
          }
        },
        "74bae842b3ee40f8a483721f0907e250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a75b33dcc394cc3a8d54906032cb502",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c24c5a3df68d4d6482d1bef5f170ca50",
            "value": 10
          }
        },
        "0fefd2e7d9dc4cd290241112dc2f1323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_812878fbaf54433aa7a501b49208f44c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8c0cad3c5cca40a589268449b227dc7c",
            "value": "‚Äá10/10‚Äá[01:02&lt;00:00,‚Äá‚Äá6.08s/it]"
          }
        },
        "aeeccda9cd0b4d1aa5c2d55bc352c372": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29deab1d5a4e4492ac0d5ee977ce5f68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffd6e7a36436452ca182ee20c72a5feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a75b33dcc394cc3a8d54906032cb502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c24c5a3df68d4d6482d1bef5f170ca50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "812878fbaf54433aa7a501b49208f44c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c0cad3c5cca40a589268449b227dc7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# rag_gpt_api.py\n",
        "\n",
        "# ‚úÖ Install required packages before running:\n",
        "# pip install openai sentence-transformers faiss-cpu pdf2image pytesseract fastapi uvicorn python-dotenv\n",
        "# Also run (Linux):\n",
        "# apt-get install -y tesseract-ocr-ben poppler-utils\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from dotenv import load_dotenv\n",
        "import openai\n"
      ],
      "metadata": {
        "id": "IlH1U9BZt0fO"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWXPri6-I_V4",
        "outputId": "65a4db07-f6e6-4fe0-e4ec-603c342e9ff1"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load OpenAI API Key\n",
        "load_dotenv()\n",
        "client = OpenAI(\n",
        "    api_key=\"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\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "sdEvRyxQH-ip"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üì• Step 1: Extract Bangla text from scanned PDF\n",
        "def extract_bangla_from_scanned_pdf(pdf_path):\n",
        "    images = convert_from_path(\"/content/drive/MyDrive/Colab Notebooks/HSC26-Bangla1st-Paper.pdf\")\n",
        "    bangla_text = \"\"\n",
        "    for img in images:\n",
        "        text = pytesseract.image_to_string(img, lang='ben')\n",
        "        bangla_text += text + \"\\n\"\n",
        "    return bangla_text.strip()\n"
      ],
      "metadata": {
        "id": "pEAmB5m-ICkX"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìÑ Load and process PDF\n",
        "pdf_path = \"HSC26-Bangla1st-Paper.pdf\"  # Ensure this is in the same folder\n",
        "raw_text = extract_bangla_from_scanned_pdf(pdf_path)\n"
      ],
      "metadata": {
        "id": "wWoNQglaIHAl"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üßπ Step 2: Clean and chunk the text\n",
        "def split_text_into_chunks(text, max_length=300):\n",
        "    sentences = re.split(r'[‡•§\\n]', text)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip()\n",
        "        if not sentence:\n",
        "            continue\n",
        "        if len(current_chunk) + len(sentence) < max_length:\n",
        "            current_chunk += sentence + \"‡•§ \"\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence + \"‡•§ \"\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "    return chunks\n",
        "\n",
        "text_chunks = split_text_into_chunks(raw_text)"
      ],
      "metadata": {
        "id": "a8ixDirAIJ6p"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîé Step 3: Embed and index chunks with FAISS\n",
        "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
        "embeddings = model.encode(text_chunks, show_progress_bar=True)\n",
        "dimension = embeddings[0].shape[0]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(np.array(embeddings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8c20503c783d44449e1cf29520099e97",
            "48bed49dbc29449f94a3719c43c00f9f",
            "74bae842b3ee40f8a483721f0907e250",
            "0fefd2e7d9dc4cd290241112dc2f1323",
            "aeeccda9cd0b4d1aa5c2d55bc352c372",
            "29deab1d5a4e4492ac0d5ee977ce5f68",
            "ffd6e7a36436452ca182ee20c72a5feb",
            "0a75b33dcc394cc3a8d54906032cb502",
            "c24c5a3df68d4d6482d1bef5f170ca50",
            "812878fbaf54433aa7a501b49208f44c",
            "8c0cad3c5cca40a589268449b227dc7c"
          ]
        },
        "id": "Bn6-xGdsIMfm",
        "outputId": "6bd33ce6-cdc3-45b1-8abe-d3de1c91e88f"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c20503c783d44449e1cf29520099e97"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_chunks(query, top_k=3):\n",
        "    query_embedding = model.encode([query])\n",
        "    distances, indices = index.search(np.array(query_embedding), top_k)\n",
        "    results = [text_chunks[i] for i in indices[0]]\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "w91kzpdzIQoP"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=\"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\"\n",
        ")\n",
        "\n",
        "\n",
        "def generate_answer_gpt(query, context_chunks):\n",
        "    context = \"\\n\".join(context_chunks[:3])\n",
        "    prompt = f\"\"\"You are a helpful assistant. Use the following context to answer the question in Bangla.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\n",
        "Answer in Bangla:\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        temperature=0.3,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n"
      ],
      "metadata": {
        "id": "mA9SKNVrVieA"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ To run this script:\n",
        "# uvicorn rag_gpt_api:app --reload --port 8000\n",
        "\n",
        "# üß™ Optional CLI test\n",
        "if __name__ == \"__main__\":\n",
        "    sample_question = \"‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ï‡ßÉ‡¶§ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶õ‡¶ø‡¶≤?\"\n",
        "    context = retrieve_chunks(sample_question)\n",
        "    print(\"üîç Context:\")\n",
        "    for c in context:\n",
        "        print(\"-\", c)\n",
        "    print(\"\\nüí¨ GPT Answer:\")\n",
        "    print(generate_answer_gpt(sample_question, context))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "_33UoBsyIgcS",
        "outputId": "fa469b63-9e1a-41fc-abda-be7cf2550db9"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Context:\n",
            "- ‡¶â‡¶™‡ßÅ‡¶°‡¶º ‡¶ï‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ ‡¶¶‡¶ø‡¶§‡ßá ‡¶¶‡ßç‡¶¨‡¶ø‡¶ß‡¶æ ‡¶π‡¶á‡¶¨‡ßá ‡¶®‡¶æ‡•§ ‡¶è‡¶∏‡¶¨ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶ï‡¶•‡¶æ‡•§ ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ, ‡¶Æ‡ßá‡¶Ø‡¶º‡ßá‡¶∞ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶Ø‡ßá ‡¶™‡¶®‡ßá‡¶∞‡ßã, ‡¶§‡¶æ‡¶á ‡¶∂‡ßÅ‡¶®‡¶ø‡¶Ø‡¶º‡¶æ ‡¶Æ‡¶æ‡¶Æ‡¶æ‡¶∞ ‡¶Æ‡¶® ‡¶≠‡¶æ‡¶∞ ‡¶π‡¶á‡¶≤‡•§ ‡¶¨‡¶Ç‡¶∂‡ßá ‡¶§‡ßã ‡¶ï‡ßã‡¶®‡ßã ‡¶¶‡ßã‡¶∑‡•§ ‡¶®‡¶æ‡¶á? ‡¶®‡¶æ, ‡¶¶‡ßã‡¶∑ ‡¶®‡¶æ‡¶á- ‡¶¨‡¶æ‡¶™ ‡¶ï‡ßã‡¶•‡¶æ‡¶ì ‡¶§‡¶æ‡¶∞ ‡¶Æ‡ßá‡¶Ø‡¶º‡ßá‡¶∞ ‡¶Ø‡ßã‡¶ó‡ßç‡¶Ø ‡¶¨‡¶∞ ‡¶ñ‡ßÅ‡¶Å‡¶ú‡¶ø‡¶Ø‡¶º‡¶æ ‡¶™‡¶æ‡¶® ‡¶®‡¶æ‡•§ ‡¶è‡¶ï‡ßá ‡¶§‡ßã ‡¶¨‡¶∞‡ßá‡¶∞ ‡¶ò‡¶æ‡¶ü ‡¶Æ‡¶π‡¶æ‡¶∞‡ßç‡¶ò, ‡¶§‡¶æ‡¶π‡¶æ‡¶∞‡•§\n",
            "- ‡¶¨‡¶ø‡¶∑‡¶Ø‡¶º‡¶ü‡¶ø ‡¶™‡¶æ‡¶∞‡¶≠‡ßá‡¶ú‡ßá‡¶∞ ‡¶ï‡¶æ‡¶®‡ßá ‡¶ó‡ßá‡¶≤‡ßá ‡¶∏‡ßá ‡¶¨‡¶æ‡¶™‡¶ï‡ßá ‡¶∏‡¶æ‡¶´ ‡¶ú‡¶æ‡¶®‡¶ø‡¶Ø‡¶º‡ßá ‡¶¶‡ßá‡¶Ø‡¶º, '‡¶∏‡ßá ‡¶¶‡¶∞‡¶¶‡¶æ‡¶Æ ‡¶¨‡¶æ ‡¶ï‡ßá‡¶®‡¶æ‡¶¨‡ßá‡¶ö‡¶æ‡¶∞ ‡¶™‡¶£‡ßç‡¶Ø ‡¶®‡¶Ø‡¶º‡•§ ‡¶∏‡ßá ‡¶è‡¶ï‡¶ú‡¶® ‡¶Æ‡¶æ‡¶®‡ßÅ‡¶∑‡¶ï‡ßá ‡¶ú‡ßÄ‡¶¨‡¶®‡¶∏‡¶ô‡ßç‡¶ó‡ßÄ ‡¶ï‡¶∞‡¶§‡ßá ‡¶è‡¶∏‡ßá‡¶õ‡ßá, ‡¶Ö‡¶™‡¶Æ‡¶æ‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶®‡¶Ø‡¶º‡•§ ‡¶´‡¶ø‡¶∞‡¶§‡ßá ‡¶π‡¶≤‡ßá ‡¶≤‡¶æ‡¶¨‡¶®‡¶ø‡¶ï‡ßá ‡¶∏‡¶ô‡ßç‡¶ó‡ßá ‡¶®‡¶ø‡¶Ø‡¶º‡ßá‡¶á ‡¶¨‡¶æ‡¶°‡¶º‡¶ø‡•§ ‡¶´‡¶ø‡¶∞‡¶¨‡ßá‡•§ '‡•§ ‡¶ï. ‡¶∂‡¶∏‡ßç‡¶§‡ßÅ‡¶®‡¶æ‡¶• ‡¶∏‡ßá‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶π‡¶æ‡¶§‡ßá ‡¶ï‡ßÄ ‡¶™‡¶∞‡¶ñ ‡¶ï‡¶∞‡¶§‡ßá ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá‡¶õ‡¶ø‡¶≤‡ßá‡¶®?‡•§\n",
            "- ‡¶®‡¶ø‡¶Ø‡¶º‡ßá ‡¶®‡¶æ‡¶∞‡ßÄ‡¶∞ ‡¶ö‡¶∞‡¶Æ ‡¶Ö‡¶¨‡¶Æ‡¶æ‡¶®‡¶®‡¶æ‡¶ï‡¶æ‡¶≤‡ßá ‡¶∂‡¶∏‡ßç‡¶§‡ßÅ‡¶®‡¶æ‡¶• ‡¶∏‡ßá‡¶®‡ßá‡¶∞ ‡¶ï‡¶®‡ßç‡¶Ø‡¶æ-‡¶∏‡¶Æ‡ßç‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡¶®‡ßá ‡¶Ö‡¶∏‡¶Æ‡ßç‡¶Æ‡¶§‡¶ø ‡¶ó‡¶≤‡ßç‡¶™‡¶ü‡¶ø‡¶∞ ‡¶∂‡ßÄ‡¶∞‡ßç‡¶∑ ‡¶Æ‡ßÅ‡¶π‡ßÇ‡¶∞‡ßç‡¶§‡•§ ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ ‡¶®‡¶ø‡¶ú‡ßá‡¶∞‡•§ ‡¶ó‡¶≤‡ßç‡¶™ ‡¶¨‡¶≤‡¶§‡ßá ‡¶ó‡¶ø‡¶Ø‡¶º‡ßá ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ô‡ßç‡¶ó‡¶æ‡¶∞‡ßç‡¶•‡ßá ‡¶ú‡¶æ‡¶®‡¶ø‡¶Ø‡¶º‡ßá ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá‡¶õ‡ßá ‡¶∏‡ßá‡¶á ‡¶Ö‡¶ò‡¶ü‡¶® ‡¶∏‡¶Ç‡¶ò‡¶ü‡¶®‡ßá‡¶∞ ‡¶ï‡¶•‡¶æ‡¶ü‡¶ø‡•§ ‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶∞ ‡¶≤‡¶ó‡ßç‡¶® ‡¶Ø‡¶ñ‡¶® ‡¶™‡ßç‡¶∞‡¶∏‡ßç‡¶§‡ßÅ‡¶§ ‡¶§‡¶ñ‡¶® ‡¶ï‡¶®‡ßç‡¶Ø‡¶æ‡¶∞‡•§\n",
            "\n",
            "üí¨ GPT Answer:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-93-3812042157.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nüí¨ GPT Answer:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_answer_gpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_question\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-92-1216857235.py\u001b[0m in \u001b[0;36mgenerate_answer_gpt\u001b[0;34m(query, context_chunks)\u001b[0m\n\u001b[1;32m     19\u001b[0m Answer in Bangla:\"\"\"\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1085\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1086\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1088\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m         )\n\u001b[0;32m-> 1256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üåê Step 5: FastAPI Web Server\n",
        "app = FastAPI()\n",
        "\n",
        "class QueryRequest(BaseModel):\n",
        "    question: str\n",
        "\n",
        "@app.post(\"/ask\")\n",
        "def ask(query: QueryRequest):\n",
        "    retrieved = retrieve_chunks(query.question)\n",
        "    answer = generate_answer_gpt(query.question, retrieved)\n",
        "    return {\n",
        "        \"question\": query.question,\n",
        "        \"retrieved_chunks\": retrieved,\n",
        "        \"answer\": answer\n",
        "    }\n"
      ],
      "metadata": {
        "id": "9Ai6PkcSIde8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}